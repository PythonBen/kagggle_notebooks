{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom torchvision import transforms, models\nfrom torchvision.transforms.functional import to_pil_image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn, optim\nfrom PIL import Image\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport copy\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-30T19:44:50.686929Z","iopub.execute_input":"2022-03-30T19:44:50.687233Z","iopub.status.idle":"2022-03-30T19:44:52.322243Z","shell.execute_reply.started":"2022-03-30T19:44:50.687157Z","shell.execute_reply":"2022-03-30T19:44:52.321527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:44:52.323836Z","iopub.execute_input":"2022-03-30T19:44:52.324065Z","iopub.status.idle":"2022-03-30T19:44:52.37823Z","shell.execute_reply.started":"2022-03-30T19:44:52.324032Z","shell.execute_reply":"2022-03-30T19:44:52.377317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import libraries\nimport albumentations\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nimport torchvision\n\nfrom sklearn import metrics, model_selection, preprocessing","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:44:55.326125Z","iopub.execute_input":"2022-03-30T19:44:55.327597Z","iopub.status.idle":"2022-03-30T19:44:57.399972Z","shell.execute_reply.started":"2022-03-30T19:44:55.327541Z","shell.execute_reply":"2022-03-30T19:44:57.399247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n\npath_input = Path('/kaggle/input/happy-whale-and-dolphin')\ndef path_exploration():\n    for path in path_input.iterdir():\n        print(path)    \n#path_exploration()\nfile_sample = \"sample_submission.csv\"\nfolders = ['train_images', 'test_images']\ndf = pd.read_csv(path_input/'train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:45:02.354861Z","iopub.execute_input":"2022-03-30T19:45:02.35563Z","iopub.status.idle":"2022-03-30T19:45:02.454791Z","shell.execute_reply.started":"2022-03-30T19:45:02.355591Z","shell.execute_reply":"2022-03-30T19:45:02.45391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path and datas\n#root_dir = '/kaggle/input/plant-pathology-2021-fgvc8/'\nroot_dir = '/kaggle/input/happy-whale-and-dolphin/'\n#IMAGE_PATH = root_dir + 'train_images/'\nIMAGE_PATH = root_dir + 'train_images/'\n#IMAGE_PATH_TEST = root_dir + 'img_sz_256/'\nIMAGE_PATH_TEST  = root_dir + 'test_images/'\nIMAGE_SIZE = (64,96)\ncurrent_folder  = \"/kaggle/working/\"\nLR = 3e-3\nEPOCHS=6\nTRAIN_BS=16\nVALID_BS=16\nN_classes = 30","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:55:29.924879Z","iopub.execute_input":"2022-03-30T19:55:29.925137Z","iopub.status.idle":"2022-03-30T19:55:29.930794Z","shell.execute_reply.started":"2022-03-30T19:55:29.925111Z","shell.execute_reply":"2022-03-30T19:55:29.92994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read the data\ndef get_data(root_dir_csv):\n    df_raw = pd.read_csv(root_dir_csv  + 'train.csv')\n    df_raw.rename(columns={'species': 'labels'}, inplace=True)\n    print(df_raw.shape)\n    print(df_raw.head())\n\n    # label encoding\n    label_encoder = preprocessing.LabelEncoder()\n    label_encoder.fit(df_raw['labels'])\n    df_raw['labels'] = label_encoder.transform(df_raw['labels'])\n    #print(df_raw.head())\n    #df = df_raw.drop(['labels'], axis = 1).reset_index(drop=True)\n \n    print(df.head())\n    df_raw.to_csv(current_folder+'df.csv', index=False)\n    return label_encoder, df_raw\n\nlabel_encoder, df_raw = get_data(root_dir)\ndf = pd.read_csv(current_folder + 'df.csv')\nprint(df.head())\nprint(df.shape)\n\ndef make_train_valid_df():\n    df_train, df_valid = model_selection.train_test_split(\n        df,\n        test_size=0.2,\n        random_state=42,\n        stratify=df.labels.values\n    )\n    df_train = df_train.reset_index(drop=True)\n    df_valid = df_valid.reset_index(drop=True)\n    print(df_train.shape)\n    print(df_valid.shape)\n    print(df_train.head())\n\n    df_train.to_csv(current_folder +'df_train.csv', index=False)\n    df_valid.to_csv(current_folder +'df_valid.csv', index=False)\n\nmake_train_valid_df()\n\ndf_train = pd.read_csv(current_folder + 'df_train.csv')\ndf_valid = pd.read_csv(current_folder + 'df_valid.csv')\n\n# define toy_dataset\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:45:15.005008Z","iopub.execute_input":"2022-03-30T19:45:15.005791Z","iopub.status.idle":"2022-03-30T19:45:15.464101Z","shell.execute_reply.started":"2022-03-30T19:45:15.005742Z","shell.execute_reply":"2022-03-30T19:45:15.463354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(root_dir  + 'train.csv')\nlist_species = sorted(df.species.unique())\nprint(list_species)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:45:23.072344Z","iopub.execute_input":"2022-03-30T19:45:23.073203Z","iopub.status.idle":"2022-03-30T19:45:23.140967Z","shell.execute_reply.started":"2022-03-30T19:45:23.07315Z","shell.execute_reply":"2022-03-30T19:45:23.140168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_mapping = {}\nfor item, idx in enumerate(list_species):\n    dict_mapping[item] = idx\nprint(dict_mapping)\n\nint_to_name = {}\nfor k,v in dict_mapping.items():\n    int_to_name[v] = k\nprint(int_to_name)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:45:26.219223Z","iopub.execute_input":"2022-03-30T19:45:26.219924Z","iopub.status.idle":"2022-03-30T19:45:26.226697Z","shell.execute_reply.started":"2022-03-30T19:45:26.219877Z","shell.execute_reply":"2022-03-30T19:45:26.225997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_mapping[9]","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:28:23.449602Z","iopub.execute_input":"2022-03-23T14:28:23.449902Z","iopub.status.idle":"2022-03-23T14:28:23.455395Z","shell.execute_reply.started":"2022-03-23T14:28:23.449865Z","shell.execute_reply":"2022-03-23T14:28:23.454698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the dataset\ndef datasets():\n    # define the dataset\n    train_image_paths = [os.path.join(IMAGE_PATH,x) for x in df_train.image.values]\n    train_targets = [x for x in df_train.labels.values]\n\n    valid_image_paths = [os.path.join(IMAGE_PATH,x) for x in df_valid.image.values]\n    valid_targets = [x for x in df_valid.labels.values]\n\n\n    #test_image_paths = [f.as_posix() for f in (Path(IMAGE_PATH_TEST)).iterdir()]\n    #test_targets = df_sample.labels.values\n\n    assert(len(train_image_paths) == len(train_targets))\n    assert(len(valid_image_paths) == len(valid_targets))\n    return train_image_paths, train_targets, valid_image_paths, valid_targets\n#assert(len(test_image_paths) == len(test_targets))\ntrain_image_paths, train_targets, valid_image_paths, valid_targets = datasets()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:45:49.518966Z","iopub.execute_input":"2022-03-30T19:45:49.519408Z","iopub.status.idle":"2022-03-30T19:45:49.616991Z","shell.execute_reply.started":"2022-03-30T19:45:49.519372Z","shell.execute_reply":"2022-03-30T19:45:49.616334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'traindataset:{len(train_targets)}, validdataset:{len(valid_targets)}')\nprint(f'traindataset:{len(train_image_paths)}, validdataset:{len(valid_image_paths)}')","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:45:54.053231Z","iopub.execute_input":"2022-03-30T19:45:54.053518Z","iopub.status.idle":"2022-03-30T19:45:54.058505Z","shell.execute_reply.started":"2022-03-30T19:45:54.053466Z","shell.execute_reply":"2022-03-30T19:45:54.057545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create the dataset\n\ntrain_transform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std = [0.229, 0.224, 0.225]),\n    ])\n\n\n\n\nclass MyDataset(Dataset):\n    def __init__(self, image_paths, targets,  transform=None):\n        self.image_paths = image_paths[0:10000]\n        self.targets = targets\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, item):\n        #image = read_image(self.image_paths[item])\n        image = Image.open(self.image_paths[item]).convert('RGB')\n        label = self.targets[item]\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n\n\ntrain_dataset = MyDataset(train_image_paths, train_targets, transform = train_transform)\nvalid_dataset = MyDataset(valid_image_paths, valid_targets, transform = train_transform)\nprint(len(train_dataset))\nx, y = train_dataset[1]\nprint(x.size())\nprint(type(x))\nprint(x[0:4, 0:4])\nprint(y)\n# to do: save the picture in there dimensions.","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:55:52.00371Z","iopub.execute_input":"2022-03-30T19:55:52.004146Z","iopub.status.idle":"2022-03-30T19:55:52.178513Z","shell.execute_reply.started":"2022-03-30T19:55:52.004108Z","shell.execute_reply":"2022-03-30T19:55:52.177774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model \nmodel_resnet18 = models.resnet18(pretrained=True)\nnum_ftrs = model_resnet18.fc.in_features\nprint(num_ftrs)\nmodel_resnet18.fc = nn.Linear(num_ftrs, N_classes)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:46:22.339236Z","iopub.execute_input":"2022-03-30T19:46:22.33993Z","iopub.status.idle":"2022-03-30T19:46:23.081144Z","shell.execute_reply.started":"2022-03-30T19:46:22.339892Z","shell.execute_reply":"2022-03-30T19:46:23.080295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# logistic regression\n# Create Logistic Regression Model\nclass LogisticRegressionModel(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(LogisticRegressionModel, self).__init__()\n        # Linear part\n        self.linear = nn.Linear(input_dim, output_dim)\n        # There should be logistic function right?\n        # However logistic function in pytorch is in loss function\n        # So actually we do not forget to put it, it is only at next parts\n    \n    def forward(self, x):\n        out = self.linear(x)\n        return out\n\n# Instantiate Model Class\ninput_dim = 3*IMAGE_SIZE[0]*IMAGE_SIZE[1] # size of image px*px\noutput_dim = N_classes # labels 0,1,2,3,4,5,6,7,8,9\n\n# create logistic regression model\nmodel = LogisticRegressionModel(input_dim, output_dim)\n\n# Cross Entropy Loss  \nloss_func = nn.CrossEntropyLoss()\n\n# SGD Optimizer \nlearning_rate = 0.001\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-25T16:45:01.671554Z","iopub.execute_input":"2022-03-25T16:45:01.671825Z","iopub.status.idle":"2022-03-25T16:45:01.689137Z","shell.execute_reply.started":"2022-03-25T16:45:01.671788Z","shell.execute_reply":"2022-03-25T16:45:01.688458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = 'cuda'\nelse:\n    device = 'cpu'\nprint(device)\n#in_image = (torch.rand((4,3, 32,32))).to(device)\n#in_image.size()\nmodel.to(device)\n#output = model(in_image)\n#outputs, loss, metrics = output\n#print(output.size())","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:46:38.405096Z","iopub.execute_input":"2022-03-30T19:46:38.40607Z","iopub.status.idle":"2022-03-30T19:46:38.563201Z","shell.execute_reply.started":"2022-03-30T19:46:38.40602Z","shell.execute_reply":"2022-03-30T19:46:38.562258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(model_resnet18)\nmean=[0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:22:10.887818Z","iopub.execute_input":"2022-03-23T14:22:10.888374Z","iopub.status.idle":"2022-03-23T14:22:10.892304Z","shell.execute_reply.started":"2022-03-23T14:22:10.888328Z","shell.execute_reply":"2022-03-23T14:22:10.891496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(dataset=train_dataset, batch_size=TRAIN_BS, shuffle=True)\nvalid_dl = DataLoader(dataset=valid_dataset, batch_size=VALID_BS, shuffle=False)\nx, y = next(iter(train_dl))\nprint(x.size())\nprint(y.size())\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:56:11.479986Z","iopub.execute_input":"2022-03-30T19:56:11.480237Z","iopub.status.idle":"2022-03-30T19:56:13.39489Z","shell.execute_reply.started":"2022-03-30T19:56:11.480209Z","shell.execute_reply":"2022-03-30T19:56:13.394154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loss function and optimizer\nloss_func = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_resnet18.parameters(), lr = LR)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:56:18.072451Z","iopub.execute_input":"2022-03-30T19:56:18.072725Z","iopub.status.idle":"2022-03-30T19:56:18.080542Z","shell.execute_reply.started":"2022-03-30T19:56:18.072695Z","shell.execute_reply":"2022-03-30T19:56:18.079765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = 'cuda'\nelse:\n    device = 'cpu'\nprint(device)\nin_image = (torch.rand((4,3, 32,32))).to(device)\nin_image.size()\nmodel_resnet18.to(device)\noutput = model_resnet18(in_image)\n#outputs, loss, metrics = output\nprint(output.size())","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:56:20.592861Z","iopub.execute_input":"2022-03-23T16:56:20.593568Z","iopub.status.idle":"2022-03-23T16:56:20.614306Z","shell.execute_reply.started":"2022-03-23T16:56:20.593532Z","shell.execute_reply":"2022-03-23T16:56:20.613416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs","metadata":{"execution":{"iopub.status.busy":"2022-03-22T21:56:31.263482Z","iopub.execute_input":"2022-03-22T21:56:31.264356Z","iopub.status.idle":"2022-03-22T21:56:31.300642Z","shell.execute_reply.started":"2022-03-22T21:56:31.26431Z","shell.execute_reply":"2022-03-22T21:56:31.299887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = 'cuda'\nelse:\n    device = 'cpu'\nprint(device)\nin_image = (torch.rand((4,3, 32,32))).to(device)\nin_image.size()\nmodel.to(device)\noutput = model(in_image)\n#outputs, loss, metrics = output\nprint(output.size())","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:56:22.697829Z","iopub.execute_input":"2022-03-30T19:56:22.698085Z","iopub.status.idle":"2022-03-30T19:56:22.719405Z","shell.execute_reply.started":"2022-03-30T19:56:22.698056Z","shell.execute_reply":"2022-03-30T19:56:22.718527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val, ind = outputs.max(dim=1)\nprint(val)\nprint(ind)\nprint(loss)\nprint(metrics)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T21:51:17.70344Z","iopub.execute_input":"2022-03-17T21:51:17.703705Z","iopub.status.idle":"2022-03-17T21:51:17.713416Z","shell.execute_reply.started":"2022-03-17T21:51:17.703674Z","shell.execute_reply":"2022-03-17T21:51:17.712591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_resnet18.to(device)\ndef get_lr(opt):\n    for param_group in opt.param_groups:\n        return param_group['lr']\n\n# define learning rate scheduler\n#opt = setoptim(cnn_model)\n#lr_scheduler = ReduceLROnPlateau(opt,mode='min', factor=0.5, patience=20, verbose=1)\n#for i in range(100):\n#    lr_scheduler.step(1)\n\n# metrics\ndef metrics_batch(output, target):\n    \"\"\"count the number of correct predictions per data batch\"\"\"\n    # get output class\n    pred = output.argmax(dim=1, keepdim=True)\n    # compare output class with target class\n    corrects = pred.eq(target.view_as(pred)).sum().item()\n    # equivlent to: correts = (pred==target).sum()\n    return corrects\n\n# compute the loss per batch\ndef loss_batch(loss_func, output, target, opt=None):\n    \"\"\"compute the loss per batch\"\"\"\n    loss = loss_func(output, target)\n    with torch.no_grad():\n        metric_b = metrics_batch(output,target)\n    if opt is not None:\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n    return loss.item(), metric_b\n\n# compute the loss value and the metric for the entire dataset (epoch)\ndef loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n    \"\"\"compute the loss and metric for the entire dataset\"\"\"\n    running_loss = 0.0\n    running_metric = 0.0\n    len_data = len(dataset_dl.dataset)\n\n    for xb, yb in dataset_dl:\n        # move batch to device\n        xb = xb.to(device)\n        yb = yb.to(device)\n        # get model output\n        output = model(xb)\n        # get loss per batch\n        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n        # update running loss\n        running_loss += loss_b\n        # update running metric\n        if metric_b is not None:\n            running_metric += metric_b\n\n        # break the loop in case of sanity check:\n        if sanity_check is True:\n            break\n    # average loss value\n    loss = running_loss/float(len_data)\n    # average metric value\n    metric = running_metric/float(len_data)\n    return loss, metric\n\ndef train_val(model, params):\n    \"\"\"main function for trainning and evaluating the model on the dataset\"\"\"\n    # extract model parameters\n    num_epochs = params[\"num_epochs\"]\n    loss_func = params[\"loss_func\"]\n    opt = params[\"optimizer\"]\n    train_dl = params[\"train_dl\"]\n    val_dl = params[\"val_dl\"]\n    sanity_check = params[\"sanity_check\"]\n    lr_scheduler = params[\"lr_scheduler\"]\n    path2weights = params[\"path2weights\"]\n\n    # history of loss values in each epoch\n    loss_history = {\"train\": [], \"val\": []}\n    # history of metric values in each epoch\n    metric_history = {\"train\": [], \"val\": []}\n\n    # make a deep copy of weights for the best performing model\n    best_model_wts = copy.deepcopy(model.state_dict())\n\n    # initialize the best loss to a large value (infinite)\n    best_loss = float(\"inf\")\n\n    # define a loop to calculate the loss over an epoch\n    for epoch in range(num_epochs):\n        # get current learning rate\n        current_lr = get_lr(opt)\n        print(f'Epoch {epoch}/{num_epochs-1}, current lr={current_lr}')\n        # train model on training dataset\n        model.train()\n        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n        # collect loss and metric for training dataset\n        loss_history[\"train\"].append(train_loss)\n        metric_history[\"train\"].append(train_metric)\n\n        # evaluate mode on the validation dataset\n        model.eval()\n        with torch.no_grad():\n            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n\n            # collect loss and metric for the validation dataset\n            loss_history[\"val\"].append(val_loss)\n            metric_history['val'].append(val_metric)\n\n            # store best model\n            if val_loss < best_loss:\n                best_loss = val_loss\n                best_model_wts  = copy.deepcopy(model.state_dict())\n                # store weights into a local file\n                torch.save(model.state_dict(), path2weights)\n                print(\"copied best model weights\")\n\n            # update the learning rate schedule\n            lr_scheduler.step(val_loss)\n            if current_lr != get_lr(opt):\n                print(\"loading best model weights!\")\n                model.load_state_dict(best_model_wts)\n\n            # print the loss and accuracy values and return the trained model\n            print(f'train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy:{100*val_metric}')\n            print(\"-\"*10)\n            #load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, loss_history, metric_history\n\n\n# dict to define model parameters\nparams_model = {\"input_shape\":(3,64,128),\n                \"initial_filters\": 8,\n                \"num_fc1\": 100,\n                \"dropout_rate\": 0.25,\n                \"num_classes\": 30}\n\n\n\n# loss function, optimizer, learning_rate\n# we can either use nn.NLLLoss with the logsoftmax for the output activation of the network\n# or we can use the CrossEntropyLoss with the output activation as they are (logits)\n# loss_func = nn.NLLLoss(reduction='sum')\n#loss_func = nn.CrossEntropyLoss(reduction='sum')\n\n#opt = optim.Adam(model_resnet18.parameters(), lr=3e-4)\nlr_scheduler = ReduceLROnPlateau(optimizer,mode='min', factor=0.5, patience=20, verbose=1)\n\n# params_train\nparams_train = {\"num_epochs\": 10,\n                \"optimizer\": optimizer,\n                \"loss_func\": loss_func,\n                \"train_dl\": train_dl,\n                \"val_dl\": valid_dl,\n                \"sanity_check\": False,\n                \"lr_scheduler\": lr_scheduler,\n                \"path2weights\": \"/kaggle/working/weights.pt\"}\n\n# train and validate the model\n#cnn_model, loss_hist, metric_hist = train_val(model_resnet18, params_train)\ncnn_model, loss_hist, metric_hist = train_val(model_resnet18, params_train)\n\n# Train - validation progess\nnum_epochs = params_train[\"num_epochs\"]\n\n# plot loss progress\nplt.subplot(211)\nplt.title(\"Train-Val Loss\")\nplt.plot(range(1, num_epochs + 1), loss_hist[\"train\"], label=\"train\")\nplt.plot(range(1, num_epochs + 1), loss_hist[\"val\"], label=\"val\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Training epochs\")\nplt.legend()\nplt.show()\n\n# plot accuracy progress\nplt.subplot(212)\n#plt.title(\"Train-Val Accuracy\")\nplt.plot(range(1, num_epochs + 1), metric_hist[\"train\"], label=\"train\")\nplt.plot(range(1, num_epochs + 1), metric_hist[\"val\"], label=\"val\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Training epochs\")\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:56:28.455424Z","iopub.execute_input":"2022-03-30T19:56:28.456267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"6144/64\n","metadata":{"execution":{"iopub.status.busy":"2022-03-25T16:46:57.979194Z","iopub.execute_input":"2022-03-25T16:46:57.979799Z","iopub.status.idle":"2022-03-25T16:46:57.984986Z","shell.execute_reply.started":"2022-03-25T16:46:57.979766Z","shell.execute_reply":"2022-03-25T16:46:57.984195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_data = Path('/kaggle/working')\nfor f in path_data.iterdir():\n    print(f)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T13:26:21.689906Z","iopub.execute_input":"2022-03-23T13:26:21.690382Z","iopub.status.idle":"2022-03-23T13:26:21.696227Z","shell.execute_reply.started":"2022-03-23T13:26:21.690341Z","shell.execute_reply":"2022-03-23T13:26:21.695253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inference\ndef re_normalize(x, mean = mean, std = std):\n        x_r = x.clone()\n        for c, (mean_c, std_c) in enumerate(zip(mean,std)):\n            x_r[c] *= std_c\n            x_r[c] += mean_c\n        return x_r\n\n    # display figure\ndef plot_fig(img):\n    plt.figure(figsize=(20, 20))\n    img_r = re_normalize(img)\n    ax1 = plt.subplot(1, 4, 1)\n    ax1.set_title(\"image\")\n    plt.imshow(to_pil_image(img_r))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:31:29.428918Z","iopub.execute_input":"2022-03-23T14:31:29.429181Z","iopub.status.idle":"2022-03-23T14:31:29.435691Z","shell.execute_reply.started":"2022-03-23T14:31:29.429151Z","shell.execute_reply":"2022-03-23T14:31:29.434804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference(n):\n        #model = Net(8)\n        model = model_resnet18\n        model.load_state_dict(torch.load(\"/kaggle/working/weights.pt\"))\n        model.eval()\n        model = model.to(\"cpu\")\n\n\n        dataiter = next(iter(valid_dl))\n        images, targets = dataiter[0], dataiter[1]\n        img1 = images[n]\n        target = targets[n]\n        output = model(img1.unsqueeze(0))\n        pred = torch.argmax(output.squeeze(), dim=0).detach().cpu().numpy()\n        plot_fig(img1)\n        return img1, target,pred","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:22:43.036956Z","iopub.execute_input":"2022-03-23T14:22:43.03723Z","iopub.status.idle":"2022-03-23T14:22:43.043873Z","shell.execute_reply.started":"2022-03-23T14:22:43.0372Z","shell.execute_reply":"2022-03-23T14:22:43.043154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1,target, pred = inference(25)\nclasse = pred.item()\n#print(int_to_name[pred])\nprint(f'target:{target}, pred:{pred}, specy pred:{dict_mapping[classe]}')\nprint(f'specy name:{dict_mapping[target.item()]}')","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:36:10.682926Z","iopub.execute_input":"2022-03-23T14:36:10.683207Z","iopub.status.idle":"2022-03-23T14:36:13.262884Z","shell.execute_reply.started":"2022-03-23T14:36:10.683177Z","shell.execute_reply":"2022-03-23T14:36:13.26217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = next(iter(valid_dl))\nprint(len(dataiter))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:01:46.409761Z","iopub.execute_input":"2022-03-23T14:01:46.410016Z","iopub.status.idle":"2022-03-23T14:01:48.778885Z","shell.execute_reply.started":"2022-03-23T14:01:46.409988Z","shell.execute_reply":"2022-03-23T14:01:48.778001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:02:35.146006Z","iopub.execute_input":"2022-03-23T14:02:35.146261Z","iopub.status.idle":"2022-03-23T14:02:35.162279Z","shell.execute_reply.started":"2022-03-23T14:02:35.146232Z","shell.execute_reply":"2022-03-23T14:02:35.161389Z"},"trusted":true},"execution_count":null,"outputs":[]}]}